# Example configuration with MCP support
provider:
  name: "openai"
  model: "gpt-4o-mini"
  # Note: Do NOT place API keys in config. Set OPENAI_API_KEY in your environment (.env)

# Model Configuration
model_settings:
  temperature: 0.7
  max_tokens: 1000
  top_p: 1.0
  frequency_penalty: 0.0
  presence_penalty: 0.0
  stop_sequences: []
  
# Request Settings
request:
  timeout: 30  # seconds
  retry:
    max_attempts: 3
    initial_delay: 1
    backoff_factor: 2
    
# Context Management
context:
  system_prompt: "You are a helpful assistant with access to a variety of tools, including external MCP tools."
  max_context_length: 16000
  memory:
    enabled: true
    max_messages: 5
    session_id: "mcp_session"
    conversation_db: "memory/conversation_history.db"
    vector_store:
      index_path: "memory/vector_store/faiss_index.idx"
      metadata_path: "memory/vector_store/metadata.pkl"
      top_k: 5
    
# Output Formatting
output:
  format: "text"
  stream: false

logging:
  level: "INFO"
  file: "yamllm.log"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# Tool Management 
tools:
  enabled: true
  tool_timeout: 10  # seconds
  tool_list: ['calculator', 'web_search', 'weather']
  # Security options
  safe_mode: false
  allow_network: true
  allow_filesystem: true
  allowed_paths: ["./"]
  blocked_domains: []
  mcp_connectors:
    - name: "zapier"
      url: "https://api.zapier.com/v1/mcp"
      authentication: "${ZAPIER_API_KEY}"
      description: "Zapier MCP connector for productivity tools"
      tool_prefix: "zapier"
      enabled: true
    - name: "custom_tools"
      url: "https://custom-mcp-server.example.com/mcp"
      authentication: "${CUSTOM_MCP_KEY}"
      description: "Custom MCP tools"
      tool_prefix: "custom"
      enabled: true

# Safety Settings
safety:
  content_filtering: true
  max_requests_per_minute: 60
  sensitive_keywords: []

thinking:
  enabled: true
  show_tool_reasoning: true
  model: gpt-4o-mini
  max_tokens: 512
  stream_thinking: true
  save_thinking: false
  thinking_temperature: 0.5
